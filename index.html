<!DOCTYPE html>
<html>

  <head>
    <meta charset='utf-8' />
    <meta http-equiv="X-UA-Compatible" content="chrome=1" />
    <meta name="description" content="Hadoop : Chaining and Managing Multiple Hadoop MapReduce Jobs Part 1: Using a BASH Shell" />

    <link rel="stylesheet" type="text/css" media="screen" href="stylesheets/stylesheet.css">

    <title>Hadoop</title>
  </head>

  <body>

    <!-- HEADER -->
    <div id="header_wrap" class="outer">
        <header class="inner">
          <a id="forkme_banner" href="https://github.com/michaelprom/Hadoop">View on GitHub</a>

          <h1 id="project_title">Hadoop</h1>
          <h2 id="project_tagline">Chaining and Managing Multiple Hadoop MapReduce Jobs Part 1: Using a BASH Shell</h2>

            <section id="downloads">
              <a class="zip_download_link" href="https://github.com/michaelprom/Hadoop/zipball/master">Download this project as a .zip file</a>
              <a class="tar_download_link" href="https://github.com/michaelprom/Hadoop/tarball/master">Download this project as a tar.gz file</a>
            </section>
        </header>
    </div>

    <!-- MAIN CONTENT -->
    <div id="main_content_wrap" class="outer">
      <section id="main_content" class="inner">
        <h1>
<a name="chaining-and-managing-multiple-hadoop-mapreduce-jobs-part-1-using-a-bash-shell" class="anchor" href="#chaining-and-managing-multiple-hadoop-mapreduce-jobs-part-1-using-a-bash-shell"><span class="octicon octicon-link"></span></a>Chaining and Managing Multiple Hadoop MapReduce Jobs Part 1: Using a BASH Shell</h1>

<p>Michael Prom &amp; Brad Rubin
11/8/2013</p>

<h3>
<a name="this-first-of-a-four-part-series-showing-how-to-chain-and-manage-multiple-mapreduce-jobs" class="anchor" href="#this-first-of-a-four-part-series-showing-how-to-chain-and-manage-multiple-mapreduce-jobs"><span class="octicon octicon-link"></span></a>This first of a four-part series showing how to chain and manage multiple MapReduce Jobs.</h3>

<hr><p>While a single MapReduce job may be sufficient for certain tasks, there may be instances where 2 or more jobs will be required.  Instead of executing jobs manually, we can automate this process using various methods.  </p>

<p>This series will show you how to chain multiple jobs together using four techniques: a shell script, within the driver code itself, using the JobControl class, and the Oozie: workflow scheduler.</p>

<h2>
<a name="the-two-mapreduce-jobs" class="anchor" href="#the-two-mapreduce-jobs"><span class="octicon octicon-link"></span></a>The Two MapReduce Jobs</h2>

<p>This is a basic WordCount problem which uses two MapReduce jobs. The first, is a standard WordCount problem. It simply outputs the word as the key and the count of the word as the value.  The second MapReduce job inverts the key and the value in the mapper. The output is a sorted list of word counts as the key and the associated word as a value.</p>

<p>This same concept can be applied to other situations as well. There may be cases where you want to use a MapReduce job to pre-process or sort the data before feeding it into another job. </p>

<h2>
<a name="the-shell-script" class="anchor" href="#the-shell-script"><span class="octicon octicon-link"></span></a>The Shell Script</h2>

<p>Using a shell script to manage the sequential execution of the jobs. </p>

<p>We will use the bash shell since it the default in most Linux distributions. Other shells will work as well. The script contains pre-define commands to be executed. <strong>Note:</strong>  Managing jobs using the shell will only allow jobs to be run sequentially. If your specific need requires the jobs to be run in parallel see the future how-tos in this series.   </p>

<p>The first step requires you to create an executable script file. We called this "WordCountInvert.sh". (Ensure that the permissions are set correcting using "CHMOD"). The bash script contains the variables to define the JAR files, input directory (shakespeare), and the commands to verify the result of the MapReduce Jobs. This script will output the results into a log file.  </p>

<p>The script file should look like the one below. Ensure that the variables are set for your needs.</p>

<p><strong>Note:</strong> COMMON_TEMP serves as the output filename of the 1st job, which is also the input to the second job.<br>
The LOG_FILE will show the output of the two MapReduce jobs and any errors if they exist.</p>

<pre><code>#!/bin/bash
# This script will run two MapReduce jobs. 
# Jar file definition

MAPREDUCE_JAR_JOB1="WordCount.jar"
MAPREDUCE_JAR_JOB2="WordCountInvert.jar"

# Job class definition. There are two main classes in this job. WordCount and WordCountInvert
MAIN_CLASS_JOB1="WordCount"
MAIN_CLASS_JOB2="WordCountInvert"
HADOOP="$( which hadoop )"
# Definition of the input directory. The shakespeare directory contains multiple text files. 
INPUT_DIRECTORY="shakespeare"
COMMON_TEMP="TEMP_DIR"
# This is the final job output directory.
FINAL_OUTPUT="JOB_CHAIN_RESULTS"
#Define the two commands to execute the jobs. 
JOB_1_CMD="${HADOOP} jar ${MAPREDUCE_JAR_JOB1} ${MAIN_CLASS_JOB1}  \ 
${INPUT_DIRECTORY} ${COMMON_TEMP}"


JOB_2_CMD="${HADOOP} jar ${MAPREDUCE_JAR_JOB2} ${MAIN_CLASS_JOB2} \
${COMMON_TEMP} ${FINAL_OUTPUT}"
# Define the command to cat the output of the directory.
CAT_FINAL_OUTPUT_CMD="${HADOOP} fs -cat  
${FINAL_OUTPUT}/part-*"
CLEANUP_CMD="${HADOOP} fs -rm -r ${COMMON_TEMP} ${FINAL_OUTPUT}"
LOG_FILE="LOG_`date +%s`.txt"

#This command will execute each job and determine status. 
#Results will be displayed in the log file. 
{
# Cleanup Command
${CLEANUP_CMD}

${JOB_1_CMD}
if [ $? -ne 0 ]
then
echo "ERROR FIRST JOB. SEE LOG."
${CLEANUP_CMD}
exit $?
fi
echo ${JOB_2_CMD}
${JOB_2_CMD}
if [  
$? -ne 0 ]
then
echo "ERROR SECOND JOB. SEE LOG."
${CLEANUP_CMD}
exit $?
fi
echo ${CAT_FINAL_OUTPUT_CMD}
${CAT_FINAL_OUTPUT_CMD}

${CLEANUP_CMD}
exit 0
} &amp;&gt; ${LOG_FILE}
</code></pre>

<h2>
<a name="file-execution" class="anchor" href="#file-execution"><span class="octicon octicon-link"></span></a>File Execution</h2>

<p>You can simply execute the file using ./WordCountInvert.csh from the command line (ensure x is set in the permissions). You can place multiple echo commands within the file and view the log file when complete.</p>

<h2>
<a name="pros-and-cons" class="anchor" href="#pros-and-cons"><span class="octicon octicon-link"></span></a>Pros and Cons</h2>

<p>As noted in above, you can scale this up to many jobs. Since it is done in the shell, no recompiling is needed. However, as noted jobs run in this manner can only be run sequentially. As the number of jobs increases the more lines needed in the script file. The following parts in this series will describe more efficient ways to managing large number of jobs. </p>

<h2>
<a name="references" class="anchor" href="#references"><span class="octicon octicon-link"></span></a>References</h2>

<p>Miner and Shook. <em>MapReduce Design Patterns: Building Effective Algorithms and Analytics for Hadoop and Other Systems.</em> O'Reilly 2013</p>
      </section>
    </div>

    <!-- FOOTER  -->
    <div id="footer_wrap" class="outer">
      <footer class="inner">
        <p class="copyright">Hadoop maintained by <a href="https://github.com/michaelprom">michaelprom</a></p>
        <p>Published with <a href="http://pages.github.com">GitHub Pages</a></p>
      </footer>
    </div>

    

  </body>
</html>
